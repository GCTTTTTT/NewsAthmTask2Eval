{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb753d6a-106c-4fe1-851c-189749ea87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# 连接到服务器A上的数据库\n",
    "db_server_a = mysql.connector.connect(\n",
    "  host=\"120.25.223.26\",\n",
    "  user=\"root\",\n",
    "  password=\"26Ukffx1SX>q\",\n",
    "  database=\"NR_new\"\n",
    ")\n",
    "\n",
    "# 连接到服务器B上的数据库\n",
    "db_server_b = mysql.connector.connect(\n",
    "  host=\"172.16.234.200\",\n",
    "  user=\"dg_news\",\n",
    "  password=\"dg_news\",\n",
    "  database=\"dg_crawler\"\n",
    ")\n",
    "\n",
    "# 创建游标对象\n",
    "cursor_a = db_server_a.cursor()\n",
    "cursor_b = db_server_b.cursor()\n",
    "\n",
    "try:\n",
    "    # 查询dg_clawler.news表中满足时间条件的数据\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        news.id, \n",
    "        news.title, \n",
    "        news.body, \n",
    "        news.category1, \n",
    "        news.images, \n",
    "        news.pub_time, \n",
    "        news.website_id,\n",
    "        website.url\n",
    "    FROM \n",
    "        dg_crawler.news\n",
    "    JOIN\n",
    "        common_website.website ON news.website_id = website.id\n",
    "    WHERE \n",
    "        news.pub_time BETWEEN '2024-01-01' AND '2024-04-01' and news.language_id=1779\n",
    "    \"\"\"\n",
    "    cursor_b.execute(query)\n",
    "    print(\"1\")\n",
    "    # 遍历查询结果并插入到NR.article表中\n",
    "    for (id, title, body, category1, images, pub_time, website_id, website_url) in cursor_b:\n",
    "        # print(len(body))\n",
    "        # if len(images)>10000:\n",
    "        #     print(len(images))\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO NR_new.Article \n",
    "        (art_id, art_title, art_content, art_type, art_image_url, art_time, art_cus_id, website_id, website_url)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        values = (id, title, body, category1, images, pub_time, 582, website_id, website_url)\n",
    "        cursor_a.execute(insert_query, values)\n",
    "    print(\"1\")\n",
    "    # 提交更改\n",
    "    db_server_a.commit()\n",
    "\n",
    "    print(\"数据插入成功\")\n",
    "\n",
    "except mysql.connector.Error as error:\n",
    "    print(f\"数据插入失败: {error}\")\n",
    "\n",
    "finally:\n",
    "    # 关闭游标和数据库连接\n",
    "    cursor_a.close()\n",
    "    cursor_b.close()\n",
    "    db_server_a.close()\n",
    "    db_server_b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987eb0bc-13d5-44ee-9078-9fd4c87a812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "数据插入成功\n"
     ]
    }
   ],
   "source": [
    "# NR_new_dev\n",
    "import mysql.connector\n",
    "\n",
    "# 连接到服务器A上的数据库\n",
    "db_server_a = mysql.connector.connect(\n",
    "  host=\"120.25.223.26\",\n",
    "  user=\"root\",\n",
    "  password=\"26Ukffx1SX>q\",\n",
    "  database=\"NR_new_dev\"\n",
    ")\n",
    "\n",
    "# 连接到服务器B上的数据库\n",
    "db_server_b = mysql.connector.connect(\n",
    "  host=\"172.16.234.200\",\n",
    "  user=\"dg_news\",\n",
    "  password=\"dg_news\",\n",
    "  database=\"dg_crawler\"\n",
    ")\n",
    "\n",
    "# 创建游标对象\n",
    "cursor_a = db_server_a.cursor()\n",
    "cursor_b = db_server_b.cursor()\n",
    "\n",
    "try:\n",
    "    # 查询dg_clawler.news表中满足时间条件的数据\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        news.id, \n",
    "        news.title, \n",
    "        news.body, \n",
    "        news.category1, \n",
    "        news.images, \n",
    "        news.pub_time, \n",
    "        news.website_id,\n",
    "        website.url\n",
    "    FROM \n",
    "        dg_crawler.news\n",
    "    JOIN\n",
    "        common_website.website ON news.website_id = website.id\n",
    "    WHERE \n",
    "        news.pub_time BETWEEN '2024-03-13' AND '2024-03-13' and news.language_id=1779\n",
    "    \"\"\"\n",
    "    cursor_b.execute(query)\n",
    "    print(\"1\")\n",
    "    # 遍历查询结果并插入到NR.article表中\n",
    "    for (id, title, body, category1, images, pub_time, website_id, website_url) in cursor_b:\n",
    "        # print(len(body))\n",
    "        # if len(images)>10000:\n",
    "        #     print(len(images))\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO NR_new_dev.Article \n",
    "        (art_id, art_title, art_content, art_type, art_image_url, art_time, art_cus_id, website_id, website_url)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        values = (id, title, body, category1, images, pub_time, 582, website_id, website_url)\n",
    "        cursor_a.execute(insert_query, values)\n",
    "    print(\"1\")\n",
    "    # 提交更改\n",
    "    db_server_a.commit()\n",
    "\n",
    "    print(\"数据插入成功\")\n",
    "\n",
    "except mysql.connector.Error as error:\n",
    "    print(f\"数据插入失败: {error}\")\n",
    "\n",
    "finally:\n",
    "    # 关闭游标和数据库连接\n",
    "    cursor_a.close()\n",
    "    cursor_b.close()\n",
    "    db_server_a.close()\n",
    "    db_server_b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d7d839-0330-471b-a6e1-e2d19c293f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询数据库中2024-03-02 ~ 2024-03-11的数据用于评估\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# 连接数据库\n",
    "conn = mysql.connector.connect(\n",
    "  host=\"172.16.234.200\",\n",
    "  user=\"dg_news\",\n",
    "  password=\"dg_news\",\n",
    "  database=\"dg_crawler\"\n",
    ")\n",
    "\n",
    "# 执行SQL查询\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM news\n",
    "    WHERE pub_time BETWEEN '2024-03-02' AND '2024-03-11' and news.language_id=1779\n",
    "\"\"\"\n",
    "\n",
    "# 将查询结果存入DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# 关闭数据库连接\n",
    "conn.close()\n",
    "\n",
    "# 将DataFrame写入CSV文件\n",
    "df.to_csv(\"./datasets/news_20240302_20240311.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19328a9d-3165-4007-88f9-3bdd98e7038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-default",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
